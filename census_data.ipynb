{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da14c729",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pandas pymongo sqlalchemy streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae2855d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data_url = 'C:\\Courses\\census_2011.csv'  # Change to your dataset path\n",
    "df = pd.read_csv(data_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185d21ce",
   "metadata": {},
   "source": [
    "# Task 1: Rename Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5b06b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "df.rename(columns={\n",
    "    'State name': 'State/UT',\n",
    "    'District name': 'District',\n",
    "    'Male_Literate': 'Literate_Male',\n",
    "    'Female_Literate': 'Literate_Female',\n",
    "    'Rural_Households': 'Households_Rural',\n",
    "    'Urban_Households': 'Households_Urban',\n",
    "    'Age_Group_0_29': 'Young_and_Adult',\n",
    "    'Age_Group_30_49': 'Middle_Aged',\n",
    "    'Age_Group_50': 'Senior_Citizen',\n",
    "    'Age not stated': 'Age_Not_Stated',\n",
    "    'Households_with_TV_Computer_Laptop_Telephone_mobile_phone_and_Scooter_Car': 'Household_with_ammunities',\n",
    "    'Type_of_latrine_facility_Night_soil_disposed_into_open_drain_Households': 'Type_of_latrine_facility_Night',\n",
    "    'Type_of_latrine_facility_Flush_pour_flush_latrine_connected_to_other_system_Households': 'Type_of_latrine_facility_Flush',\n",
    "    'Not_having_latrine_facility_within_the_premises_Alternative_source_Open_Households': 'Not_having_latrine_facility',\n",
    "    'Main_source_of_drinking_water_Handpump_Tubewell_Borewell_Households': 'Main_source_of_drinking_water_Handpump',\n",
    "    'Main_source_of_drinking_water_Other_sources_Spring_River_Canal_Tank_Pond_Lake_Other_sources__Households': 'Main_source_of_drinking_water_Other',\n",
    "}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce255d7",
   "metadata": {},
   "source": [
    "# Task 2: Standardize State/UT Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c5ad84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_state_name(name):\n",
    "    words = name.split()\n",
    "    return ' '.join([word.capitalize() if word != 'and' else word.lower() for word in words])\n",
    "\n",
    "df['State/UT'] = df['State/UT'].apply(standardize_state_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7724f900",
   "metadata": {},
   "source": [
    "# Task 3: Handle New State Formation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09311a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_state_formation(df, telangana_file, ladakh_districts=[\"Leh\", \"Kargil\"]):\n",
    "    with open('C:\\Courses\\Telangana.txt', \"r\") as file:\n",
    "        telangana_districts = file.read().splitlines()\n",
    "\n",
    "    df.loc[df[\"District\"].isin(telangana_districts), \"State/UT\"] = \"Telangana\"\n",
    "    df.loc[df[\"District\"].isin(ladakh_districts), \"State/UT\"] = \"Ladakh\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3480067",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_ladakh = df[df[\"State/UT\"] == \"Ladakh\"]\n",
    "#df_ladakh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8236ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Telangana = df[df[\"State/UT\"] == \"Telangana\"]\n",
    "#df_Telangana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5004f5",
   "metadata": {},
   "source": [
    "# Task 4: Handle Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5830c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_missing_data(df):\n",
    "    # Calculate and fill missing values\n",
    "    df['Population'] = df['Male'] + df['Female']\n",
    "    df['Literate'] = df['Literate_Male'] + df['Literate_Female']\n",
    "    df['Population'] = df[['Young_and_Adult', 'Middle_Aged', 'Senior_Citizen', 'Age_Not_Stated']].sum(axis=1)\n",
    "    df['Households'] = df['Households_Rural'] + df['Households_Urban']\n",
    "    missing_data = df.isnull().mean() * 100\n",
    "    return df, missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720f5767",
   "metadata": {},
   "source": [
    "# Task 5: Save Data to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5445184c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2ae22e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "717f7fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: Save Data to MongoDB (Task 5)\n",
    "def save_to_mongodb(df):\n",
    "    client = MongoClient('mongodb://localhost:27017/')\n",
    "    db = client['cleaned_census_data']\n",
    "    collection = db['census']\n",
    "    \n",
    "    # Clear any existing data in the collection (optional, based on use case)\n",
    "    collection.delete_many({})\n",
    "    \n",
    "    # Convert DataFrame to dictionary format and insert into MongoDB\n",
    "    collection.insert_many(df.to_dict('records'))\n",
    "    print(\"Data saved to MongoDB.\")\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3dd76c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2: Fetch Data from MongoDB (for Task 6)\n",
    "def fetch_from_mongodb():\n",
    "    client = MongoClient('mongodb://localhost:27017/')\n",
    "    db = client['cleaned_census_data']\n",
    "    collection = db['census']\n",
    "    \n",
    "    # Fetch data from MongoDB and load it into a DataFrame\n",
    "    data = pd.DataFrame(list(collection.find()))\n",
    "    print(\"Data fetched from MongoDB.\")\n",
    "    client.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f8bc7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3: Upload Data to MySQL (Task 6)\n",
    "def upload_to_mysql(df, username, password, database_name):\n",
    "    # Create SQLAlchemy engine to connect to MySQL\n",
    "    try:\n",
    "        engine = create_engine(f'mysql+pymysql://{username}:{password}@localhost/{database_name}')\n",
    "        connection = engine.connect()\n",
    "        print(\"Connection to MySQL database successful.\")\n",
    "        \n",
    "        # Replace table if it exists or create new table if not\n",
    "        df.to_sql('cleaned_census_data', con=engine, if_exists='replace', index=False)\n",
    "        print(\"Data uploaded to MySQL successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting to or uploading data to MySQL: {e}\")\n",
    "    \n",
    "    finally:\n",
    "        if 'connection' in locals():\n",
    "            connection.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "19cb7b82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to MongoDB.\n",
      "Data fetched from MongoDB.\n"
     ]
    }
   ],
   "source": [
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Read cleaned census data from CSV\n",
    "    df = pd.read_csv(\"C:\\Courses\\cleaned_census_data.csv\")\n",
    "\n",
    "    # Task 5: Save data to MongoDB\n",
    "    save_to_mongodb(df)\n",
    "\n",
    "    # Task 6: Fetch data from MongoDB\n",
    "    fetched_df = fetch_from_mongodb()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2156ee39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to MySQL database successful.\n",
      "Data uploaded to MySQL successfully.\n"
     ]
    }
   ],
   "source": [
    "# Task 6: Upload fetched data to MySQL\n",
    "username = 'root'         # Replace with your MySQL username\n",
    "password = 'root123'      # Replace with your MySQL password\n",
    "database_name = 'cleaned_census_data'  # Ensure this database exists in MySQL\n",
    "\n",
    "upload_to_mysql(fetched_df, username, password, database_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "69d03684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternate Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75e342f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection to MySQL database successful.\n",
      "DataFrame uploaded successfully.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Replace with your actual MySQL credentials and database details\n",
    "username = 'root'\n",
    "password = 'root123'\n",
    "host = 'localhost'\n",
    "database_name = 'cleaned_census_data'\n",
    "\n",
    "try:\n",
    "    # Create a connection to the database\n",
    "    engine = create_engine(f'mysql+pymysql://{username}:{password}@{host}/{database_name}')\n",
    "    \n",
    "    # Check if the connection is successful\n",
    "    with engine.connect() as connection:\n",
    "        print(\"Connection to MySQL database successful.\")\n",
    "        \n",
    "        # Assuming df is already defined and contains the DataFrame to be uploaded\n",
    "        df = pd.read_csv(\"C:\\Courses\\cleaned_census_data.csv\")  # Load your cleaned data\n",
    "        \n",
    "        # Upload the DataFrame to MySQL\n",
    "        df.to_sql('cleaned_census_data', con=engine, if_exists='replace', index=False)\n",
    "        print(\"DataFrame uploaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error connecting to or uploading data to MySQL: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6810aef3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baeff3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6975792",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
